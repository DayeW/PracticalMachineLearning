---
title:""PML Project: Prediction Assignment"""
output:
  html_document: default
  pdf_document: default
---

# Background

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. 

# Instructions

The project asks to predict the manner in which the subjects did the exercise using the `classe` variable, with focus on variables with `belt, forearm, arm, dumbell`. The report must include how the model is built, how cross validation is used, what the expected out of sample error is, and why I made the choices that I did. I will also use my prediction model to predict 20 different test cases.


# Loading/Processing Data

```{r echo = TRUE}
library(knitr)
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
```

First, the testing and training data are loaded into my working directory.

```{r echo = TRUE}
setwd("~/Desktop/Work/Coursera/Prediction")

URLtrain <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(URLtrain, "./train.csv", method = "curl")

URLtest <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(URLtest, "./test.csv", method = "curl")

train <- read.csv("train.csv")
test <- read.csv("test.csv") 
```

Let's look at the data.

```{r echo = TRUE}
head(train[, 1:10], 3) #has NAs <- will need to remove
unique(train$classe) #has levels A B C D E
dim(train); dim(test)
```

In the training data, there are missing values that may affect the accuracy of our predictions, so they will be removed. The `classe` variable also has 5 levels, which indicates what the prediction will look like. 

## Processing Data

First, I'll need to get rid of the near zero covariates - this means that variables with a variance close to zero (no variation) will be deducted from the dataset to produce an accurate model. 

```{r echo = TRUE}
nzcov <- nearZeroVar(train, saveMetrics = TRUE)
train <- train[, !nzcov$nzv]
test <- test[, !nzcov$nzv]
```

Here, I remove most of the missing values from the dataset. Variables consisting of 95% and greater missing values are excluded.  

```{r echo = TRUE}
removeNA <- sapply(train, function(x) mean(is.na(x)) > 0.95)
train <- train[, removeNA == FALSE]
test <- test[, removeNA == FALSE]
head(train[, 1:10], 3)
```

The columns left do not have many NAs which will affect our model. However, the first 7 columns contain observations that are not needed for our predictions. These variables will be excluded from the datasets as well.

```{r echo = TRUE}
train <- train[, -(1:7)]
test <- test[, -(1:7)]
dim(train); dim(test)
```

## Partitioning the Data

In order to create our model, I partition the data using the `createDataPartition` function from the `caret` package. This splits the dataset into 60% training and 40% for the test data, as recommended by the course. 

```{r echo = TRUE}
set.seed(12345)
inTrain <- createDataPartition(y = train$classe, p = 0.6, list = FALSE)
training <- train[inTrain, ]
testing <- train[-inTrain, ]
dim(training); dim(testing)
```

The dimensions of the training and testing data reflect the data partition, and now I am ready to build a prediction model.


# Models for Prediction

In this section, I will build two different prediction models using the Decision Tree algorithm and Random Forest algorithm. Due to system run-time issues, I do not use Boosting, Linear Discriminant Analaysis, or Naive Bayes algorithms to build the predictor. Since using Decision Trees may result in overfitting, I expect that using the Random Forest algorithm may produce a more accurate prediction model, considering the random selection of a subset of observations. For **cross validation**, I use the `confusionMatrix` function to get an estimate of the out of sample error.


## With Decision Tree Modeling

I use the `train` function to fit the data into a prediction model. First I check and plot if using the Decision Tree algorithm may be an accurate predictor for our test data.


```{r echo = TRUE, results = "hide"}
modelFit <- train(classe ~., data = training, method = "rpart")
modelFit
modelFit$finalModel
rpart.plot(modelFit$finalModel)
```

After seeing the variability in the plot, I considered pruning the plot down to fewer variables; however, I wanted to see instead the accuracy and error rate before continuing on with the Decision Tree algorithm. 

```{r echo = TRUE}
prediction <- predict(modelFit, newdata = testing)
cM <- confusionMatrix(prediction, testing$classe)
cM$overall
cM$table
(error <- 1 - 0.603) #error = 1 - accuracy
```

The accuracy of using the Decision Tree model is about 0.603, or 60.3%,  which is not very high. Additionally, the error rate is 0.397, calculated by 1 minus the accuracy. This indicates that the Decision Tree model is not an accurate predictor for the test data. 


## With Random Forests

I use the `randomForest` function to fit the training data into a prediction model, since my Decision Tree model does not have high accuracy. 

```{r echo = TRUE}
set.seed(12345)
modelFit1 <- randomForest(classe ~., data = training, method = "class")
modelFit1$finalModel
```

```{r echo = TRUE}
plot(modelFit1)
prediction1 <- predict(modelFit1, newdata = testing, type = "class")
cM1 <- confusionMatrix(prediction1, testing$classe)
cM1$overall
cM1$table
(error1 <- 1 - 0.994) #error = 1 - accuracy
```

Based off the results, I see that the accuracy using a model built with Random Forest algorithm is 0.994, or 99.4%, which is very high. In addition, the error rate, calculated by 1 minus the accuracy, is 0.006, which is low. Using this model indicates that about 99% of our prediction is accurate, high above the 95% confidence threshold. 


## Conclusion and Predictor Function

In conclusion, the Random Forest algorithm builds an accurate predictor for this dataset, and I use the following to generate predictions for the assignment.

```{r echo = TRUE}
predictionsRF <- predict(modelFit1, newdata = test)
```

